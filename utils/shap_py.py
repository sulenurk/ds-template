# -*- coding: utf-8 -*-
"""shap_py.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xcA3TBGmEvS8fWlkycnLlVgI6quP-bdb
"""

import shap
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import os

"""    Generate SHAP explanations and plots for model predictions.

    Parameters:
    -----------
    model : trained model
        The machine learning model to explain.
    X_train_transformed : DataFrame
        Transformed training data used as background for the explainer.
    X_test_transformed : DataFrame
        Transformed test data to explain.
    sample_index : int
        Index of the test sample to explain in detail.
    top_n_features : int
        Number of top features to display in summary and waterfall plots.
    save_path : str or None
        Directory to save the plots. If None, plots are not saved.
    model_type : str
        Model type to select appropriate SHAP explainer ('tree' or 'other').
"""

def shap_values(model_info, df, model_type='tree'):

  model = model_info['model']

  # Choose appropriate SHAP explainer
  if model_type == 'tree':
    explainer = shap.TreeExplainer(model)
  else:
    explainer = shap.Explainer(model, df)

  # Compute SHAP values
  return explainer(df)

def global_analysis(shap_values, X_test, top_n_features=10, save_path=None):

  # Plot: Feature Importance (Bar Summary)
  shap.summary_plot(shap_values, X_test, plot_type="bar", max_display=top_n_features, show=False)
  plt.title("Feature Importance (SHAP)")
  if save_path:
      plt.savefig(f"{save_path}/shap_summary_bar.png", bbox_inches='tight', dpi=300)
  plt.show()

  # Plot: SHAP Value Distribution (Dot Summary)
  shap.summary_plot(shap_values, X_test, max_display=top_n_features, show=False)
  plt.title("SHAP Value Distribution")
  if save_path:
      plt.savefig(f"{save_path}/shap_summary_dot.png", bbox_inches='tight', dpi=300)
  plt.show()

  # Plot: SHAP Heatmap (for small datasets only)
  try:
      if X_test.shape[0] <= 100:  # avoid overload on large data
          shap.plots.heatmap(shap_values, show=False)
          plt.title("SHAP Heatmap")
          if save_path:
              plt.savefig(f"{save_path}/shap_heatmap.png", bbox_inches='tight', dpi=300)
          plt.show()
  except Exception as e:
      print(f"Heatmap plot could not be generated: {e}")

def index_charts(shap_values, sample_index, top_n_features=10, save_path=None):
  # Plot 3: Waterfall Plot for Specific Prediction
  shap.plots.waterfall(shap_values[sample_index], max_display=top_n_features, show=False)
  plt.title(f"Waterfall Plot - Sample {sample_index}")
  if save_path:
      plt.savefig(f"{save_path}/waterfall_sample_{sample_index}.png", bbox_inches='tight', dpi=300)
  plt.show()

  # Plot 4: SHAP Decision Plot
  try:
      shap.plots.decision(shap_values[sample_index], show=False)
      plt.title(f"Decision Plot - Sample {sample_index}")
      if save_path:
          plt.savefig(f"{save_path}/decision_plot_sample_{sample_index}.png", bbox_inches='tight', dpi=300)
      plt.show()
  except Exception as e:
      print(f"Decision plot could not be generated: {e}")

def index_feature(shap_values, X_test, save_path=None):

  # Create directory if save_path is given
  if save_path:
    os.makedirs(save_path, exist_ok=True)

  # Dependence Plot for Top Feature
  try:
      shap_values_abs = np.abs(shap_values.values).mean(axis=0)
      top_feature_idx = np.argsort(shap_values_abs)[-1]
      top_feature_name = X_test.columns[top_feature_idx]
      shap.plots.scatter(shap_values[:, top_feature_idx], show=False)
      plt.title(f"Dependence Plot - {top_feature_name}")
      if save_path:
          plt.savefig(f"{save_path}/dependence_plot_{top_feature_name}.png", bbox_inches='tight', dpi=300)
      plt.show()
  except Exception as e:
      print(f"Dependence plot could not be generated: {e}")